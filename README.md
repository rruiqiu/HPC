# High Performance Computing Labs

### Lab 1 – Dense Linear Algebra Optimization  
Optimized General Matrix-Matrix Multiplication (GEMM) and General Matrix-Vector Multiplication (GEMV) using cache-aware tiling and AVX vectorization for improved CPU performance.

### Lab 2 – Sparse Matrix Operations  
Implemented Sparse Matrix-Matrix Multiplication (SpMM) and Sparse Matrix-Vector Multiplication (SpMV) using efficient sparse data structures, tiling, and vectorization to accelerate computation on sparse inputs.

### Lab 3 – Parallel Matrix Multiplication with OpenMP  
Introduced OpenMP-based parallelism to speed up GEMM and SpMM computations, with configurable thread count and loop scheduling strategy.

### Lab 4 – GPU Acceleration with CUDA and OpenCL  
Developed and optimized GEMM implementations using both CUDA and OpenCL, leveraging GPU parallelism and memory management for high-throughput matrix computation.
